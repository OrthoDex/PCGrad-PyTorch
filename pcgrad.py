# -*- coding: utf-8 -*-
"""PCGrad - AIHC Spring 2020

Automatically generated by Colaboratory.

"""

"""PCGrad PyTorch

WIP implementation of https://github.com/tianheyu927/PCGrad in PyTorch
"""

import torch
import torch.nn.functional as F
import torch.nn as nn

import numpy as np
import random

from operator import mul
from functools import reduce

import os
from multiprocessing import Pool

def pc_grad_update(gradient_list, num_workers=8):
  '''
  PyTorch implementation of PCGrad.
  Gradient Surgery for Multi-Task Learning: https://arxiv.org/pdf/2001.06782.pdf

  Arguments:
    gradient_list (Iterable[Tensor] or Tensor): an iterable of Tensorsthat will 
    have gradients with respect to parameters for each task.

  Returns:
    List of gradients with PCGrad applied.
  '''

  assert type(gradient_list) is list
  assert len(gradient_list) != 0
  num_tasks = len(gradient_list)
  np.random.shuffle(gradient_list)

  def flatten_and_store_dims(param_grad, acc):
    output, grad_dim = acc

    if grad_dim is not None:
      grad_dim.append(tuple(param_grad.shape))
    output = torch.cat([output, torch.flatten(param_grad)])
    return output, grad_dim

  def restore_dims(grad_task, chunk_dims):
    ## chunk_dims is a list of tensor shapes
    chunk_sizes = [reduce(mul, dims, 1) for dims in chunk_dims]
    
    grad_chunk = torch.split(grad_task, split_size_or_sections=chunk_sizes)
    resized_chunks = []
    for index, grad in enumerate(grad_chunk): # TODO(speedup): convert to map since they are faster
      grad = torch.reshape(grad, chunk_dims[index])
      resized_chunks.append(grad)

    return resized_chunks

  def project_gradients(grad_task):
    """
    Subtracts projected gradient components for each grad in gradient_list
    if it conflicts with input gradient.

    Argument:
      grad_task (Tensor): A tensor for a gradient

    Returns:
      Component subtracted gradient
    """

    def get_projected_gradient_sum(k, conflict_gradient_candidate):
      # no need to store dims of candidate since we are not changing it in the array
      conflict_gradient_candidate, _ = reduce(flatten_and_store_dims, conflict_gradient_candidate, ([], None))
      
      inner_product = torch.dot(torch.flatten(grad_task), torch.flatten(conflict_gradient_candidate))
      if inner_product >= 0.:
        # print('conflict')
        ## no conflict, don't do heavy operations
        return 0

      proj_direction = inner_product / torch.norm(conflict_gradient_candidate)**2

      return proj_direction
    
    grad_task, grad_dim = reduce(flatten_and_store_dims, grad_task, ([], []))
    pool = Pool(num_workers)
    # Note: A pool within a pool might not be a good idea because of the zombie reaping problem
    results = pool.starmap(get_projected_gradient_sum, zip(list(range(num_tasks)), gradient_list))
  
    grad_task = grad_task - reduce(lambda a, b: a + b, results)
    # get back grad_task
    grad_task = restore_dims(grad_task, grad_dim)
    
    return grad_task

  flatmappool = Pool(num_workers)
  flattened_grad_task = list(flatmappool.map(project_gradients, gradient_list))

  yield flattened_grad_task




